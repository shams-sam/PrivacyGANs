{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.config as cfg\n",
    "from src.data import get_loader\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([8, 3, 2, 8, 0, 4, 6, 8, 4, 6]),\n",
       " tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = get_loader('mnist', 10, True)\n",
    "for data, target in loader:\n",
    "    break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0, 81, 73, 88, 26, 53, 30, 53, 86, 55]),\n",
       " tensor([ 4, 19,  1,  8, 13,  4,  0,  4,  5,  0])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = get_loader('cifar_100', 10, True)\n",
    "for data, target in loader:\n",
    "    break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " tensor([1, 1, 0, 0, 0, 1, 0, 0, 1, 1]),\n",
       " tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0]),\n",
       " tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0]),\n",
       " tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1]),\n",
       " tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 1]),\n",
       " tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 1]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 1]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1]),\n",
       " tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 1])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = get_loader('celeba', 10, 'train')\n",
    "for data, target in loader:\n",
    "    break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 60000\n",
      "\tTrain torch.Size([1000, 1, 28, 28]) torch.Size([1000]) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 10000\n",
      "\tValid torch.Size([1000, 1, 28, 28]) torch.Size([1000]) \n",
      "\n",
      "cifar_100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 50000\n",
      "\tTrain torch.Size([1000, 3, 32, 32]) torch.Size([1000]) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 10000\n",
      "\tValid torch.Size([1000, 3, 32, 32]) torch.Size([1000]) \n",
      "\n",
      "celeba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 162770\n",
      "\tTrain torch.Size([770, 3, 218, 178]) torch.Size([770, 40]) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples: 19867\n",
      "\tValid torch.Size([867, 3, 218, 178]) torch.Size([867, 40]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['mnist', 'cifar_100', 'celeba']\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    for train, tr in zip([True, False], ['train', 'valid']):\n",
    "        loader = get_loader(\n",
    "            dataset,\n",
    "            1000,\n",
    "            train if dataset in ['mnist', 'cifar_100'] else tr,\n",
    "            False\n",
    "        )\n",
    "        num_samples = 0\n",
    "        for data, label in loader:\n",
    "            num_samples += data.shape[0]\n",
    "        print('Num Samples: {}'.format(num_samples))\n",
    "        print('\\tTrain' if train else '\\tValid', data.shape, label.shape, '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "tensor(0.1307) tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'mnist'\n",
    "loader = get_loader(dataset, cfg.num_trains[dataset], True)\n",
    "for data, target in loader:\n",
    "    continue\n",
    "print(data.shape)\n",
    "print(data.mean(), data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "tensor(0.5071) tensor(0.2673)\n",
      "tensor(0.4865) tensor(0.2564)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4409) tensor(0.2762)\n"
     ]
    }
   ],
   "source": [
    "dataset, num_channels = 'cifar_100', 3\n",
    "loader = get_loader(dataset, cfg.num_trains[dataset], True)\n",
    "for data, target in loader:\n",
    "    continue\n",
    "print(data.shape)\n",
    "for nc in range(num_channels):\n",
    "    print(data[:, nc, :, :].mean(), data[:, nc, :, :].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:01<00:04,  1.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:02<00:03,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:03<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:04<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:01<00:06,  1.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:03<00:04,  1.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:05<00:03,  1.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:06<00:01,  1.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:08<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:08<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel means: [0.50707516 0.48654891 0.44091781]\n",
      "channel stds: [0.26733406 0.25643733 0.27614959]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset, num_channels = 'cifar_100', 3\n",
    "loader = get_loader(dataset, 10000, True)\n",
    "sum_channels = np.zeros((num_channels,))\n",
    "for data, target in tqdm(loader, total=len(loader)):\n",
    "    for nc in range(num_channels):\n",
    "        sum_channels[nc] += data[:, nc, :, :].sum()\n",
    "mean_channels = sum_channels/(\n",
    "    cfg.num_trains[dataset] * cfg.input_sizes[dataset][1] * cfg.input_sizes[dataset][2])\n",
    "abs_diff_channeles = np.zeros((num_channels,))\n",
    "for data, target in tqdm(loader, total=len(loader)):\n",
    "    for nc in range(num_channels):\n",
    "        abs_diff_channeles[nc] += np.power(data[:, nc, :, :] - mean_channels[nc], 2).sum()\n",
    "std_channels = np.power(abs_diff_channeles/(\n",
    "    cfg.num_trains[dataset] * cfg.input_sizes[dataset][1] * cfg.input_sizes[dataset][2]), 0.5)\n",
    "print(\"\\nchannel means: {}\\nchannel stds: {}\".format(mean_channels, std_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1/17 [00:13<03:39, 13.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 2/17 [00:27<03:26, 13.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 3/17 [00:42<03:16, 14.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 4/17 [00:56<03:01, 13.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 5/17 [01:10<02:48, 14.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 6/17 [01:23<02:30, 13.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 7/17 [01:35<02:13, 13.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 8/17 [01:49<02:02, 13.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 9/17 [02:03<01:48, 13.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 10/17 [02:17<01:35, 13.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 11/17 [02:29<01:20, 13.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 12/17 [02:42<01:05, 13.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 13/17 [02:55<00:51, 12.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 14/17 [03:08<00:39, 13.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 15/17 [03:22<00:26, 13.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 16/17 [03:35<00:13, 13.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 17/17 [03:38<00:00, 10.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 17/17 [03:38<00:00, 12.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1/17 [00:29<07:45, 29.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 2/17 [00:56<07:10, 28.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 3/17 [01:27<06:50, 29.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 4/17 [01:55<06:16, 28.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 5/17 [02:25<05:49, 29.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 6/17 [02:55<05:23, 29.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 7/17 [03:24<04:53, 29.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 8/17 [03:52<04:19, 28.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 9/17 [04:20<03:49, 28.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 10/17 [04:48<03:20, 28.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 11/17 [05:16<02:50, 28.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 12/17 [05:44<02:21, 28.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 13/17 [06:12<01:52, 28.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 14/17 [06:41<01:24, 28.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 15/17 [07:09<00:56, 28.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 16/17 [07:39<00:28, 28.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 17/17 [07:47<00:00, 22.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 17/17 [07:47<00:00, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel means: [0.50634537 0.42580516 0.3831881 ]\n",
      "channel stds: [0.31064245 0.29035588 0.28972666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset, num_channels = 'celeba', 3\n",
    "loader = get_loader(dataset, 10000, 'train')\n",
    "sum_channels = np.zeros((num_channels,))\n",
    "for data, target in tqdm(loader, total=len(loader)):\n",
    "    for nc in range(num_channels):\n",
    "        sum_channels[nc] += data[:, nc, :, :].sum()\n",
    "mean_channels = sum_channels/(\n",
    "    cfg.num_trains[dataset] * cfg.input_sizes[dataset][1] * cfg.input_sizes[dataset][2])\n",
    "abs_diff_channeles = np.zeros((num_channels,))\n",
    "for data, target in tqdm(loader, total=len(loader)):\n",
    "    for nc in range(num_channels):\n",
    "        abs_diff_channeles[nc] += np.power(data[:, nc, :, :] - mean_channels[nc], 2).sum()\n",
    "std_channels = np.power(abs_diff_channeles/(\n",
    "    cfg.num_trains[dataset] * cfg.input_sizes[dataset][1] * cfg.input_sizes[dataset][2]), 0.5)\n",
    "print(\"\\nchannel means: {}\\nchannel stds: {}\".format(mean_channels, std_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 77,  7, 14, 95, 12, 71, 47, 15, 45]) [16 13  7  7  0  9 10 17 11 13]\n"
     ]
    }
   ],
   "source": [
    "from common.data import get_loader\n",
    "from common.cifar_100 import CIFAR100 as cifar\n",
    "\n",
    "loader = get_loader('cifar_100', 10, True)\n",
    "for data, target in loader:\n",
    "    print(target, cifar.get_coarse_class_ids(target))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sea'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar._idx_to_fine_class[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar._label_encoder.inverse_transform([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/root/anaconda3/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "WorkSheet.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
