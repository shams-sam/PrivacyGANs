{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from common.utility import to_categorical, torch_device\n",
    "from notebook_utils.generate_gaussian import generate_gaussian\n",
    "from notebook_utils.eigan import Encoder, Discriminator\n",
    "from notebook_utils.federated import federated\n",
    "from notebook_utils.eigan_training import distributed, centralized\n",
    "from notebook_utils.utility import class_plot, to_numpy\n",
    "import notebook_utils.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='gpu'\n",
    "device = torch_device(device=device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 2048\n",
    "NUM_TRIALS = 10\n",
    "VAR1 = 1\n",
    "VAR2 = 1\n",
    "NUM_NODES = 2\n",
    "PHI=1\n",
    "BATCHSIZE=512\n",
    "\n",
    "phi = 0.8\n",
    "delta = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = {}\n",
    "for run in [0] + list(range(8,10)):\n",
    "    print('run: ---------------------------------------->', run)\n",
    "    history = {}\n",
    "    for NUM_NODES in range(2, 11):\n",
    "    # for NUM_NODES in [10]:\n",
    "        VAR_ADD = 1\n",
    "        X, y_1, y_2 = [], [], []\n",
    "        for _ in range(NUM_NODES):\n",
    "            data = generate_gaussian((VAR1+VAR_ADD)/10, (VAR2+VAR_ADD)/10, MAX//NUM_NODES, 1)\n",
    "            X.append(data[0])\n",
    "            y_1.append(data[1])\n",
    "            y_2.append(data[2])\n",
    "            VAR_ADD += 1\n",
    "\n",
    "        print('='*80)\n",
    "        print('{} NODE DATA'.format(NUM_NODES))\n",
    "        print('='*80)\n",
    "        for _ in range(NUM_NODES):\n",
    "            print('@node {}, X: {}, y_1: {}, y2: {}'.format(_, X[_].shape, y_1[_].shape, y_2[_].shape))\n",
    "\n",
    "        w_1 = []\n",
    "        w_2 = []\n",
    "        train_loaders = []\n",
    "        X_valids = []\n",
    "        X_trains = []\n",
    "        y_1_valids = []\n",
    "        y_1_trains = []\n",
    "        y_2_valids = []\n",
    "        y_2_trains = []\n",
    "        for node_idx in range(NUM_NODES):\n",
    "            X_local = X[node_idx]\n",
    "            y_1_local = y_1[node_idx]\n",
    "            y_2_local = y_2[node_idx]\n",
    "\n",
    "            X_train, X_valid, y_1_train, y_1_valid, y_2_train, y_2_valid = train_test_split(\n",
    "                X_local, y_1_local, y_2_local, test_size=0.2, stratify=pd.DataFrame(\n",
    "                    np.concatenate((y_1_local, y_2_local), axis=1)\n",
    "                ))\n",
    "            print('@node {}: X_train, X_valid, y_1_train, y_1_valid, y_2_train, y_2_valid'.format(node_idx))\n",
    "            print(X_train.shape, X_valid.shape, y_1_train.shape, y_1_valid.shape, y_2_train.shape, y_2_valid.shape)\n",
    "\n",
    "            w = np.bincount(y_1_train.flatten())\n",
    "            w_1.append(sum(w)/w)\n",
    "            w = np.bincount(y_2_train.flatten())\n",
    "            w_2.append(sum(w)/w)\n",
    "            print('@node {}: class weights => w1, w2'.format(node_idx), w_1, w_2)\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_valid = scaler.transform(X_valid)\n",
    "\n",
    "            width = 0.35\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(13, 4))\n",
    "            ax1.bar(np.unique(y_1_train.flatten()), np.bincount(y_1_train.flatten()), width, color='b')\n",
    "            ax1.bar(np.unique(y_2_train.flatten())+width, np.bincount(y_2_train.flatten()), width, color='r')\n",
    "            ax1.legend(['ally', 'adversary'])\n",
    "\n",
    "            y_1_train = to_categorical(y_1_train)\n",
    "            y_2_train = to_categorical(y_2_train)\n",
    "            y_1_valid = to_categorical(y_1_valid)\n",
    "            y_2_valid = to_categorical(y_2_valid)\n",
    "\n",
    "            X_train = torch.Tensor(X_train)\n",
    "            y_1_train = torch.Tensor(y_1_train)\n",
    "            y_2_train = torch.Tensor(y_2_train)\n",
    "\n",
    "            X_valids.append(torch.Tensor(X_valid))\n",
    "            y_1_valids.append(torch.Tensor(y_1_valid))\n",
    "            y_2_valids.append(torch.Tensor(y_2_valid))\n",
    "\n",
    "            X_trains.append(X_train)\n",
    "            y_1_trains.append(y_1_train)\n",
    "            y_2_trains.append(y_2_train)\n",
    "\n",
    "            class_plot(X_train, np.argmax(y_1_train, axis=1), np.argmax(y_2_train, axis=1), \n",
    "                       'normalized train set @ node {}'.format(node_idx), ax2)\n",
    "            class_plot(X_valid, np.argmax(y_1_valid, axis=1), np.argmax(y_2_valid, axis=1), \n",
    "                       'normalized valid set @ node {}'.format(node_idx), ax3)\n",
    "\n",
    "            print('@node {}: tensor sizes =>'.format(node_idx), X_train.shape, X_valid.shape, y_1_train.shape, y_1_valid.shape, y_2_train.shape, y_2_valid.shape)\n",
    "\n",
    "            train_loaders.append(DataLoader(TensorDataset(X_train, y_1_train, y_2_train), batch_size=BATCHSIZE, shuffle=True))\n",
    "\n",
    "        alpha = 1\n",
    "        lr_encd = 0.0001\n",
    "        lr_1 = 0.0001\n",
    "        lr_2 = 0.0001\n",
    "        n_iter_gan = 501\n",
    "\n",
    "        input_size = X_train.shape[1]\n",
    "        hidden_size = input_size*8\n",
    "        output_size = 2\n",
    "\n",
    "        global_params = {}\n",
    "        encoders = {}\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print('EIGAN Training w/ phi={} and delta={}'.format(phi, delta))\n",
    "        print(\"-\"*80)\n",
    "        encoders['{}_{}'.format(phi, delta)] = distributed(NUM_NODES, phi, delta, \n",
    "                               X_trains, X_valids, \n",
    "                               y_1_trains, y_1_valids,\n",
    "                               y_2_trains, y_2_valids,\n",
    "                               input_size, hidden_size, output_size, \n",
    "                               alpha, lr_encd, lr_1, lr_2, w_1, w_2,\n",
    "                               train_loaders, n_iter_gan, device, global_params)\n",
    "\n",
    "        pkl.dump(encoders, open(\n",
    "            'encoders_num_nodes{}_phi{}_delta{}.pkl'.format(NUM_NODES, phi, delta), 'wb'))\n",
    "\n",
    "        X_train = torch.cat(X_trains, dim=0).to(device)\n",
    "        X_valid = torch.cat(X_valids, dim=0).to(device)\n",
    "        y_1_train = torch.cat(y_1_trains, dim=0).to(device)\n",
    "        y_1_valid = torch.cat(y_1_valids, dim=0).to(device)\n",
    "        y_2_train = torch.cat(y_2_trains, dim=0).to(device)\n",
    "        y_2_valid = torch.cat(y_2_valids, dim=0).to(device)\n",
    "\n",
    "        X_trains = [_.to(device) for _ in X_trains]\n",
    "        X_valids = [_.to(device) for _ in X_valids]\n",
    "        y_1_trains = [_.to(device) for _ in y_1_trains]\n",
    "        y_1_valids = [_.to(device) for _ in y_1_valids]\n",
    "        y_2_trains = [_.to(device) for _ in y_2_trains]\n",
    "        y_2_valids = [_.to(device) for _ in y_2_valids]\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_train, y_1_train, y_2_train), batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "        encoder = centralized(X_train, X_valid,\n",
    "                              y_1_train, y_1_valid,\n",
    "                              y_2_train, y_2_valid,\n",
    "                              input_size, hidden_size, output_size,\n",
    "                              alpha, lr_encd, lr_1, lr_2, w_1[0], w_2[0],\n",
    "                              train_loader, n_iter_gan, device)\n",
    "\n",
    "        pkl.dump(encoder, open('encoder_num_nodes{}_central_compare.pkl'.format(NUM_NODES), 'wb'))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print('ALLY: BASELINE')\n",
    "        print(\"-\"*80)\n",
    "        history['baseline_ally_{}'.format(NUM_NODES)] = metrics.centralized(None, \n",
    "                                                     input_size, hidden_size, output_size, \n",
    "                                                     X_train, X_valid, y_1_train, y_1_valid, \n",
    "                                                     w_1[0], device)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print('ADVERSARY: BASELINE')\n",
    "        print(\"-\"*80)\n",
    "        history['baseline_advr_{}'.format(NUM_NODES)] = metrics.centralized(None, \n",
    "                                                     input_size, hidden_size, output_size, \n",
    "                                                     X_train, X_valid, y_2_train, y_2_valid, \n",
    "                                                     w_2[0], device)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print('ALLY: CENTRALIZED')\n",
    "        print(\"-\"*80)\n",
    "        history['centralized_ally_{}'.format(NUM_NODES)] = metrics.centralized(encoder, \n",
    "                                                     input_size, hidden_size, output_size, \n",
    "                                                     X_train, X_valid, y_1_train, y_1_valid, \n",
    "                                                     w_1[0], device)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print('ADVERSARY: CENTRALIZED')\n",
    "        print(\"-\"*80)\n",
    "        history['centralized_advr_{}'.format(NUM_NODES)] = metrics.centralized(encoder, \n",
    "                                                     input_size, hidden_size, output_size, \n",
    "                                                     X_train, X_valid, y_2_train, y_2_valid, \n",
    "                                                     w_2[0], device)\n",
    "\n",
    "        for key, encd in encoders.items():\n",
    "            print(\"-\"*80)\n",
    "            print('ALLY: {}'.format(key))\n",
    "            print(\"-\"*80)\n",
    "            history['decentralize_ally_{}'.format(NUM_NODES)] = metrics.distributed(encd, NUM_NODES,\n",
    "                                                                 input_size, hidden_size, output_size, \n",
    "                                                                 X_trains, X_valids, y_1_trains, y_1_valids, \n",
    "                                                                 w_1[0], device)\n",
    "            print(\"-\"*80)\n",
    "            print('ADVERSARY: {}'.format(key))\n",
    "            print(\"-\"*80)\n",
    "            history['decentralized_advr_{}'.format(NUM_NODES)] = metrics.distributed(encd, NUM_NODES,\n",
    "                                                                         input_size, hidden_size, output_size, \n",
    "                                                                         X_trains, X_valids, y_2_trains, y_2_valids, \n",
    "                                                                         w_2[0], device)\n",
    "\n",
    "        baseline_ally = []\n",
    "        baseline_advr = []\n",
    "        eigan_ally = []\n",
    "        eigan_advr = []\n",
    "        dist_x = []\n",
    "        dist_ally = []\n",
    "        dist_advr = []\n",
    "\n",
    "        tmp = history['baseline_ally_{}'.format(NUM_NODES)][3]\n",
    "        baseline_ally.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['baseline_advr_{}'.format(NUM_NODES)][3]\n",
    "        baseline_advr.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['centralized_ally_{}'.format(NUM_NODES)][3]\n",
    "        eigan_ally.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['centralized_advr_{}'.format(NUM_NODES)][3]\n",
    "        eigan_advr.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "        dist_x.append(phi)\n",
    "        tmp = history['decentralize_ally_{}'.format(NUM_NODES)][3]\n",
    "        dist_ally.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['decentralized_advr_{}'.format(NUM_NODES)][3]\n",
    "        dist_advr.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "\n",
    "        ax1.hlines(y=eigan_ally[0], xmin=-0.1, xmax=1.1, color='b', linestyle='dashed')\n",
    "        ax1.hlines(y=eigan_advr[0], xmin=-0.1, xmax=1.1, color='r', linestyle='dashed')\n",
    "        ax1.bar(np.array(dist_x)-0.025, dist_ally, width=0.05, color='b')\n",
    "        ax1.bar(np.array(dist_x)+0.025, dist_advr, width=0.05, color='r')\n",
    "        ax1.set_xticks(dist_x)\n",
    "        ax1.set_xlim(left=-0.1, right=1.1)\n",
    "        ax1.legend(['c-ally', 'c-adversary', 'd-ally', 'd-adversary'], loc='lower right')\n",
    "        ax1.set_xlabel('fraction of parameters shared')\n",
    "        ax1.set_ylabel('f1 score')\n",
    "        ax1.set_title('(b)', y=-0.3)\n",
    "        ax1.grid()\n",
    "\n",
    "        plt.rcParams.update({'font.size': 14})\n",
    "        fig.subplots_adjust(wspace=0.3)\n",
    "        plt.savefig('distributed_eigan_comparison.png', bbox_inches='tight', dpi=300)\n",
    "    master[run] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(master, open('history_distributed_noniid_numnodes_gaussian_10_runs_0.6.pkl', 'wb'))\n",
    "# pkl.dump(history, open('history_distributed_noniid_numnodes_gaussian.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pkl.load(open('history_distributed_noniid_numnodes_gaussian_10_runs_0.6.pkl', 'rb'))\n",
    "master.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = []\n",
    "baseline_ally = np.zeros((9,))\n",
    "baseline_advr = np.zeros((9,))\n",
    "eigan_ally = np.zeros((9,))\n",
    "eigan_advr = np.zeros((9,))\n",
    "dist_ally = np.zeros((9,))\n",
    "dist_advr = np.zeros((9,))\n",
    "\n",
    "# NUM_RUNS = 10\n",
    "# for run in range(NUM_RUNS):\n",
    "NUM_RUNS = 3\n",
    "for run in [0,8,9]:\n",
    "    history = master[run]\n",
    "    baseline_ally_iter = []\n",
    "    baseline_advr_iter = []\n",
    "    eigan_ally_iter = []\n",
    "    eigan_advr_iter = []\n",
    "    dist_ally_iter = []\n",
    "    dist_advr_iter = []\n",
    "    for _ in range(2, 11):\n",
    "        if run == 0:\n",
    "            num_nodes.append(_)\n",
    "        tmp = history['baseline_ally_{}'.format(_)][2]\n",
    "        baseline_ally_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['baseline_advr_{}'.format(_)][2]\n",
    "        baseline_advr_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['centralized_ally_{}'.format(_)][2]\n",
    "        eigan_ally_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['centralized_advr_{}'.format(_)][2]\n",
    "        eigan_advr_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['decentralize_ally_{}'.format(_)][2]\n",
    "        dist_ally_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        tmp = history['decentralized_advr_{}'.format(_)][2]\n",
    "        dist_advr_iter.append(max(tmp['svm'], tmp['logistic'], tmp['mlp']))\n",
    "        \n",
    "    baseline_ally += np.array(baseline_ally_iter)    \n",
    "    baseline_advr += np.array(baseline_advr_iter)\n",
    "    eigan_ally += np.array(eigan_ally_iter)    \n",
    "    eigan_advr += np.array(eigan_advr_iter)\n",
    "    dist_ally += np.array(dist_ally_iter)    \n",
    "    dist_advr += np.array(dist_advr_iter)\n",
    "    \n",
    "baseline_ally /= NUM_RUNS    \n",
    "baseline_advr /= NUM_RUNS\n",
    "eigan_ally /= NUM_RUNS    \n",
    "eigan_advr /= NUM_RUNS\n",
    "dist_ally /= NUM_RUNS    \n",
    "dist_advr /= NUM_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_x = list(range(2, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_advr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "ax1.bar(np.array(num_nodes)-0.3, eigan_advr, width=0.2, color='r')\n",
    "ax1.bar(np.array(num_nodes), dist_advr, width=0.2, color='maroon')\n",
    "ax1.bar(np.array(num_nodes)+0.3, baseline_advr, width=0.2, color='orange')\n",
    "ax1.set_xticks(dist_x)\n",
    "# ax1.set_xlim(left=-0.1, right=1.1)\n",
    "ax1.set_ylim(top=1.0, bottom=0.4)\n",
    "# ax1.legend(['c-ally', 'c-adversary', 'd-ally', 'd-adversary'], loc='lower right')\n",
    "ax1.set_xlabel('number of nodes')\n",
    "ax1.set_ylabel('adversary accuracy')\n",
    "ax1.set_title('(a)', y=-0.3)\n",
    "ax1.grid()\n",
    "\n",
    "ax2.bar(np.array(num_nodes)-0.3, eigan_ally, width=0.2, color='r')\n",
    "ax2.bar(np.array(num_nodes), dist_ally, width=0.2, color='maroon')\n",
    "ax2.bar(np.array(num_nodes)+0.3, baseline_ally, width=0.2, color='orange')\n",
    "ax2.set_xticks(dist_x)\n",
    "# ax1.set_xlim(left=-0.1, right=1.1)\n",
    "ax2.set_ylim(top=1.0, bottom=0.6)\n",
    "ax2.legend(['EIGAN', 'D-EIGAN', 'Unencoded'], loc='upper right', prop={'size': 10})\n",
    "ax2.set_xlabel('number of nodes')\n",
    "ax2.set_ylabel('ally accuracy')\n",
    "ax2.set_title('(b)', y=-0.3)\n",
    "ax2.grid()\n",
    "\n",
    "\n",
    "markers = ['o', 'x', 'o', 'x']                                                                                                                                                                                                                                                                                                                                  \n",
    "colors = ['b', 'r']  \n",
    "X = data[0]\n",
    "y_1 = data[1]\n",
    "y_2 = data[2]\n",
    "for i in range(2):                                                                                                                                                                                                                                                                                                                                              \n",
    "    for j in range(2):                                                                                                                                                                                                                                                                                                                                          \n",
    "        tmp = X[np.intersect1d(                                                                                                                                                                                                                                                                                                                                 \n",
    "            np.where(y_1 == i)[0], np.where(y_2 == j)[0])]                                                                                                                                                                                                                                                                                                      \n",
    "        ax3.scatter(tmp[:, 0], tmp[:, 1],                                                                                                                                                                                                                                                                                                                       \n",
    "                    c=colors[i], marker=markers[2*i+j])                                                                                                                                                                                                                                                                                                         \n",
    "ax3.set_xlim(left=0, right=3)\n",
    "ax3.set_ylim(top=3, bottom=0)\n",
    "ax3.set_yticks([0, 1, 2, 3])\n",
    "ax3.set_ylabel(\"ally (reds vs blues)\")\n",
    "ax3.set_xlabel(\"adversary (x's vs o's)\")\n",
    "# ax3.axis('equal')               `\n",
    "ax3.set_title('(c)', y=-0.3)  \n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "plt.savefig('figure_distributed_noniid_numnodes_gaussian.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for change in ally/advr loss with inc in advrs/allies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ally_loss stays constant\n",
    "import pickle as pkl                                                                                                                                                                                                                                                                                                                                                \n",
    "import matplotlib.pyplot as plt                                                                                                                                                                                                                                                                                                                                     \n",
    "import matplotlib                                                                                                                                                                                                                                                                                                                                                   \n",
    "matplotlib.rcParams.update({'font.size': 12})                                                                                                                                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                                                                                                                                                                                    \n",
    "_12 = pkl.load(open('../checkpoints/mimic_centralized/n_advr_ind_gan_training_history_02_12_2020_19_30_38.pkl', 'rb'))                                                                                                                                                                                                                                                             \n",
    "_34 = pkl.load(open('../checkpoints/mimic_centralized/n_advr_ind_gan_training_history_02_12_2020_20_01_01.pkl', 'rb'))                                                                                                                                                                                                                                                             \n",
    "_56 = pkl.load(open('../checkpoints/mimic_centralized/n_advr_ind_gan_training_history_02_12_2020_23_07_22.pkl', 'rb'))                                                                                                                                                                                                                                                             \n",
    "_789 = pkl.load(open('../checkpoints/mimic_centralized/n_advr_ind_gan_training_history_02_13_2020_13_54_53.pkl', 'rb'))                                                                                                                                                                                                                                                            \n",
    "_n = pkl.load(open('../checkpoints/mimic_centralized/n_advr_ind_gan_training_history_02_13_2020_18_31_15.pkl', 'rb'))                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                                                                                                                    \n",
    "h = {1: _12, 2: _12, 3: _34, 4:_34, 5: _56, 6: _56, 7: _789, 8: _789, 9: _789, 10: _n}                                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                                                                                                                    \n",
    "orig = pkl.load(open('../checkpoints/mimic_centralized/n_ind_training_history_02_02_2020_16_15_58.pkl', 'rb'))\n",
    "loss_ind = orig['admission_type']['y_valid'][-1]\n",
    "num_ally = []                                                                                                                                                                                                                                                                                                                                                       \n",
    "loss = []                                                                                                                                                                                                                                                                                                                                                           \n",
    "for idx, hist in h.items():                                                                                                                                                                                                                                                                                                                                         \n",
    "    num_ally.append(idx)                                                                                                                                                                                                                                                                                                                                            \n",
    "    loss.append(h[idx][idx-1]['advr_valid'][-1])  \n",
    "    \n",
    "loss = np.array(loss)\n",
    "tmp = (loss_ind - loss)/loss_ind\n",
    "tmp.mean(), tmp.std(), loss.mean(), loss.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advr loss stays constant\n",
    "import pickle as pkl                                                                                                                                                                                                                                                                                                                                                  \n",
    "import matplotlib.pyplot as plt                                                                                                                                                                                                                                                                                                                                       \n",
    "import matplotlib                                                                                                                                                                                                                                                                                                                                                     \n",
    "matplotlib.rcParams.update({'font.size': 12})                                                                                                                                                                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "_13 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_03_2020_17_41_09.pkl', 'rb'))                                                                                                                                                                                                                                                                    \n",
    "_28 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_05_2020_00_23_29.pkl', 'rb'))                                                                                                                                                                                                                                                                    \n",
    "_4 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_03_2020_20_09_39.pkl', 'rb'))                                                                                                                                                                                                                                                                     \n",
    "_5 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_04_2020_00_21_50.pkl', 'rb'))                                                                                                                                                                                                                                                                     \n",
    "_67 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_04_2020_05_30_09.pkl', 'rb'))                                                                                                                                                                                                                                                                    \n",
    "_8 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_05_2020_00_23_29.pkl', 'rb'))                                                                                                                                                                                                                                                                     \n",
    "_9 = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_05_2020_18_09_03.pkl', 'rb'))                                                                                                                                                                                                                                                                     \n",
    "_n = pkl.load(open('../checkpoints/mimic_centralized/n_ind_gan_training_history_02_04_2020_20_13_29.pkl', 'rb'))                                                                                                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "h = {1: _13, 2: _28, 3: _13, 4:_4, 5: _5, 6: _67, 7: _67, 8: _8, 9: _9, 10: _n}                                                                                                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "orig = pkl.load(open('../checkpoints/mimic_centralized/n_ind_training_history_02_02_2020_16_15_58.pkl', 'rb'))                                                                                                                                                                                                                                                                       \n",
    "loss_ind = orig['admission_type']['y_valid'][-1]                                                                                                                                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                                                                                                                                                                      \n",
    "num_ally = []                                                                                                                                                                                                                                                                                                                                                         \n",
    "loss = []                                                                                                                                                                                                                                                                                                                                                             \n",
    "for idx, hist in h.items():                                                                                                                                                                                                                                                                                                                                           \n",
    "    num_ally.append(idx)                                                                                                                                                                                                                                                                                                                                              \n",
    "    loss.append(h[idx][idx-1]['advr_valid'][-1])   \n",
    "\n",
    "loss = np.array(loss)\n",
    "tmp = (loss-loss_ind)/loss_ind\n",
    "tmp.mean(), tmp.std(), loss.mean(), loss.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
