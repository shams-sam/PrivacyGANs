{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import\n",
    "- Data is downloaded and converted to pickle file\n",
    "- [Download location](http://yann.lecun.com/exdb/mnist/)\n",
    "- Extraction using mlxtend library. sample code [reference](http://rasbt.github.io/mlxtend/user_guide/data/loadlocal_mnist/)\n",
    "\n",
    "### code for importing and converting the data into pickle files\n",
    "\n",
    "The original dataset as imported from website which contributes the dataset for public usage is in unsigned byte format. The dataset is in flattened format and has single channel 28\\*28 images flattened row-wise. The images are rebuilt using one of the many codes contributed by various users working on the same dataset.\n",
    "\n",
    "For ease of use, here we have converted the dataset to standard pickle format as the library is generally more readily available on most platforms when compared to the mlxtend library originally mentioned. \n",
    "\n",
    "```python\n",
    "from mlxtend.data import loa local_mnist\n",
    "import pickle as pkl\n",
    "\n",
    "X, y = loadlocal_mnist(\n",
    "        images_path='data/MNIST/train-images-idx3-ubyte', \n",
    "        labels_path='data/MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "pkl.dump((X, y), open('data/MNIST/data.pkl', 'wb'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from expt_mnist.preprocessing import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "X_train, X_valid, y_train, y_valid = get_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "- convert data to the appropriate format and check the label against sample instances for validation.\n",
    "- data is presented in a single row vector as flattened values for 28\\*28 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Plot\n",
    "\n",
    "Plotting dataset and checking corresponding labels to ensure validity of the code that is rebuilding the dataset from original ubyte dateset downloaded. The samples are picked at random to ensure that data at random are correctly labelled and the code is working fine in rebuilding the images from flattened vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for _ in range(12):\n",
    "    idx = random.randint(0, len(X_train)-1)\n",
    "    image_row_vector = X_train[idx]\n",
    "    plt.subplot(5, 4, _+1)\n",
    "    plt.imshow(image_row_vector.reshape((28, 28, 1)).squeeze())\n",
    "    plt.title(\"label: {}\".format(y_train[0][idx]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN\n",
    "\n",
    "- Reference: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "\n",
    "Main idea of DCGAN lies in the terms of giving architecture guidelines to ensure stable training of GANs on CNNs. The main guidelines as summarized in the paper by the authors involve:\n",
    "\n",
    "- replace any pooling layer with strided convolutions in discriminator and fractional-strided convolutions in generator\n",
    "- batchnorm in both generator and discriminator\n",
    "- no fully connected hidden layers in deep networks\n",
    "- ReLU in generator for all layers but output layer which has Tanh activation\n",
    "- LeakyReLU in discriminator for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DType: torch.float32\n",
      "Cuda available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"DType: {}\\nCuda available: {}\\nDevice: {}\".format(\n",
    "    dtype.__str__(),\n",
    "    torch.cuda.is_available().__str__(),\n",
    "    device.__str__(),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- custom weight initialization called on the discriminator and generator networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants Explained\n",
    "\n",
    "- nz: encoding dimension\n",
    "- ngf: generator filters that are scaled by factors 2, 4, 8 etc.\n",
    "- ndf: disciminator filter similar to ngf\n",
    "- nc: number of channels\n",
    "- ngpu: number of physical gpus on system\n",
    "- batchSize: number of instances for SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 50\n",
    "ngf = 56\n",
    "ndf = 112\n",
    "nc = 1\n",
    "ngpu = 1\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Bias Initialization\n",
    "\n",
    "- It has been shown heuristically that weights intialized normally tend to perform better when compared to random initialization. So the first function tries to achieve this goal.\n",
    "\n",
    "- In the definition of Generator and Discriminator, sometimes the number of strides, kernel_size and pooling is adjusted to meet the final size of the output desired. \n",
    "\n",
    "- It can be seen that there are no fully connected layers in both G and D\n",
    "- Also batchnorm is applied on all layers \n",
    "- ReLU on each layer except output\n",
    "- Tanh on output layer\n",
    "\n",
    "Reference: https://github.com/pytorch/examples/tree/master/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 448, 2, 2]          89,600\n",
      "       BatchNorm2d-2            [-1, 448, 2, 2]             896\n",
      "              ReLU-3            [-1, 448, 2, 2]               0\n",
      "   ConvTranspose2d-4            [-1, 224, 4, 4]       1,605,632\n",
      "       BatchNorm2d-5            [-1, 224, 4, 4]             448\n",
      "              ReLU-6            [-1, 224, 4, 4]               0\n",
      "   ConvTranspose2d-7            [-1, 112, 8, 8]         401,408\n",
      "       BatchNorm2d-8            [-1, 112, 8, 8]             224\n",
      "              ReLU-9            [-1, 112, 8, 8]               0\n",
      "  ConvTranspose2d-10           [-1, 56, 16, 16]         100,352\n",
      "      BatchNorm2d-11           [-1, 56, 16, 16]             112\n",
      "             ReLU-12           [-1, 56, 16, 16]               0\n",
      "  ConvTranspose2d-13            [-1, 1, 28, 28]             224\n",
      "             Tanh-14            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,198,896\n",
      "Trainable params: 2,198,896\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 8.39\n",
      "Estimated Total Size (MB): 9.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 2, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 2, 2, 2,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "            return self.main(input)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "summary(netG, input_size=(50, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly,\n",
    "\n",
    "- LeakyReLU on each layer\n",
    "- BatchNorm on each layer\n",
    "- Sigmoid in last layer to ensure probabilistic output \n",
    "- Sigmoid helps apply the BCE criterion at the end on the loss for optimizer\n",
    "- BCE is binary cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 112, 16, 16]             448\n",
      "         LeakyReLU-2          [-1, 112, 16, 16]               0\n",
      "            Conv2d-3            [-1, 224, 8, 8]         401,408\n",
      "       BatchNorm2d-4            [-1, 224, 8, 8]             448\n",
      "         LeakyReLU-5            [-1, 224, 8, 8]               0\n",
      "            Conv2d-6            [-1, 448, 4, 4]       1,605,632\n",
      "       BatchNorm2d-7            [-1, 448, 4, 4]             896\n",
      "         LeakyReLU-8            [-1, 448, 4, 4]               0\n",
      "            Conv2d-9            [-1, 896, 2, 2]       6,422,528\n",
      "      BatchNorm2d-10            [-1, 896, 2, 2]           1,792\n",
      "        LeakyReLU-11            [-1, 896, 2, 2]               0\n",
      "           Conv2d-12              [-1, 1, 1, 1]           3,584\n",
      "          Sigmoid-13              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 8,436,736\n",
      "Trainable params: 8,436,736\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.01\n",
      "Params size (MB): 32.18\n",
      "Estimated Total Size (MB): 33.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 2, 2, 2, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 2, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "summary(netD, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and load\n",
    "\n",
    "- Fixing the batchsize after creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.TensorDataset(X_train.reshape(-1, 1, 28, 28), y_train[0])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "\n",
    "- need to tweak the values of learning rate for generator and discriminator\n",
    "- if the value is not optimal, discriminator might converge too soon and then generator will collapse \n",
    "- so the parameter tweaking is a must to find the right balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20][0/938] Loss_D: 1.2705 Loss_G: 24.4019 D(x): 0.5538 D(G(z)): 0.4436 / 0.0000\n",
      "[0/20][100/938] Loss_D: 4.1315 Loss_G: 1.0600 D(x): 0.0425 D(G(z)): 0.0051 / 0.3553\n",
      "[0/20][200/938] Loss_D: 0.1559 Loss_G: 5.2541 D(x): 0.9252 D(G(z)): 0.0663 / 0.0067\n",
      "[0/20][300/938] Loss_D: 0.1018 Loss_G: 12.1528 D(x): 0.9305 D(G(z)): 0.0001 / 0.0001\n",
      "[0/20][400/938] Loss_D: 0.1896 Loss_G: 6.6923 D(x): 0.9847 D(G(z)): 0.1435 / 0.0028\n",
      "[0/20][500/938] Loss_D: 0.0437 Loss_G: 5.9683 D(x): 0.9809 D(G(z)): 0.0229 / 0.0055\n",
      "[0/20][600/938] Loss_D: 0.1225 Loss_G: 10.5519 D(x): 0.9226 D(G(z)): 0.0000 / 0.0002\n",
      "[0/20][700/938] Loss_D: 0.5237 Loss_G: 8.7696 D(x): 0.9983 D(G(z)): 0.3208 / 0.0004\n",
      "[0/20][800/938] Loss_D: 0.0829 Loss_G: 7.1338 D(x): 0.9923 D(G(z)): 0.0696 / 0.0014\n",
      "[0/20][900/938] Loss_D: 0.4460 Loss_G: 9.4363 D(x): 0.9634 D(G(z)): 0.2876 / 0.0002\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result/DCGAN_MNIST/real_samples.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cce2d5d2c726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         vutils.save_image(real_cpu,\n\u001b[1;32m     48\u001b[0m                 \u001b[0;34m'%s/real_samples.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 normalize=True)\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         vutils.save_image(fake.detach(),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, nrow, padding, normalize, range, scale_each, pad_value, format)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2153\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result/DCGAN_MNIST/real_samples.png'"
     ]
    }
   ],
   "source": [
    "niter = 20\n",
    "outf = 'result/DCGAN_MNIST'\n",
    "\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i %100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "    if epoch % 2 == 0:\n",
    "        vutils.save_image(real_cpu,\n",
    "                '%s/real_samples.png' % outf,\n",
    "                normalize=True)\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "                '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(netD, 'models/netD.pkl')\n",
    "torch.save(netG, 'models/netG.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0th Epoch\n",
    "![](result/DCGAN_MNIST/fake_samples_epoch_000.png)\n",
    "\n",
    "### 4th Epoch\n",
    "![](result/DCGAN_MNIST/fake_samples_epoch_004.png)\n",
    "\n",
    "### 8th Epoch\n",
    "![](result/DCGAN_MNIST/fake_samples_epoch_008.png)\n",
    "\n",
    "### 12th Epoch\n",
    "![](result/DCGAN_MNIST/fake_samples_epoch_012.png)\n",
    "\n",
    "### 18th Epoch\n",
    "![](result/DCGAN_MNIST/fake_samples_epoch_018.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Try to see if there are any patterns in the random walks generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_1 = torch.randn(1, nz, 1, 1, device=device)\n",
    "fn_2 = torch.randn(1, nz, 1, 1, device=device)\n",
    "fn_r = torch.cat((fn_1, fn_2, (fn_1+fn_2)/2), 0)\n",
    "fk_r = netG(fn_r)\n",
    "fk_1.shape, fk_2.shape, fk_r.shape\n",
    "\n",
    "vutils.save_image(fk_r.detach(),\n",
    "                '%s/%s.png' % (outf, 'fk_test'),\n",
    "                normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](result/DCGAN_MNIST/fk_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
